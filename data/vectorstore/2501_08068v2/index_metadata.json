{
  "model_name": "sentence-transformers/all-MiniLM-L6-v2",
  "embedding_dim": 384,
  "similarity_metric": "cosine",
  "num_vectors": 7,
  "metadata": [
    {
      "chunk_id": "2501_chunk_0",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "A Roadmap to Guide the Integration of LLMs in Hierarchical Planning IsraelPuerta-Merino,CarlosNu \u0301n \u0303ez-Molina,PabloMesejo,JuanFerna \u0301ndez-Olivares UniversityofGranada,Spain AndalusianInstituteofDataScienceandComputationalIntelligence(DaSCI) israelpm01@ugr.es,ccaarlos@ugr.es,pmesejo@go.ugr.es,faro@decsai.ugr.es Abstract Tofacilitateevaluationandcomparisonsamongmethods, weproposeastandardizeddatasetandbenchmarkingframe- RecentadvancesinLargeLanguageModels(LLMs)arefoswork based on the 2023 International Planning Competitering their integration into several reasoning-related fields, includingAutomatedPlanning(AP).However,theirintegration (IPC-2023) HTN tracks, the most recent competition tion into Hierarchical Planning (HP), a subfield of AP that forHPsolvers.Specifically,wesuggestusingthetotal-order leverageshierarchicalknowledgetoenhanceplanningperfortrackoftheIPC-2023datasetasabenchmarkdataset.1 Asa mance,remainslargelyunexplored.Inthispreliminarywork, baseline, we implement and evaluate a basic LLM Planner weproposearoadmaptoaddressthisgapandharnessthepo- (direct planning using an LLM without any improvement tentialofLLMsforHP.Tothisend,wepresentataxonomy strategies), the simplest method of our taxonomy, on this ofintegrationmethods,exploringhowLLMscanbeutilized dataset. We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle. Additionally, we provide a benchetal.2024),oneofthehighest-performingLLMsavailable, mark with a standardized dataset for evaluating the perforandthemodelthatweplantouseinsubsequentexperiments. manceoffutureLLM-basedHPapproaches,andpresentini- We also provide the results from PandaDealer-agile-lama tialresultsforastate-of-the-artHPplannerandLLMplanner. Asexpected,thelatterexhibitslimitedperformance(3%cor- (Olz, Ho \u0308ller, and Bercher 2023), the IPC-2023 Total-Order rect plans, and none with a correct hierarchical decomposi- Satisficingtrackwinnerandstate-of-the-artHPsolver. tion)butservesasavaluablebaselineforfutureapproaches. In summary, this work offers a roadmap to guide the future research in the integration of LLMs and HP, which is Introduction provided through two main contributions: the taxonomy of LLMinHPintegrationmethods,illustratingthemagnitude Hierarchical Planning (HP) is a subfield within Automated of this field and revealing how much work remains to be Planning (AP) comprising planning methods that incorpodone;andtheproposedbenchmark,providingatoolforthe rate hierarchical knowledge. This hierarchical knowledge evaluation and comparison of developed and future methcan be leveraged to speed up planning and, also, to inods.Wehopethatthisroadmapwillinspireandguidefuture tegrate human expert problem-solving knowledge. While researchinthispromisingyetunderexploredfield. Large Language Models (LLMs) are being gradually integratedinvariousAIdomains,includingAP,theirapplication to HP remains underexplored, with only a few studies tan- Taxonomy gentiallyaddressingthistopic(Yang,Zhang,andHou2024; Daietal.2024;Tse2024;Songetal.2023).Ourcontribu- To bridge the gap between HP and existing LLM Integrationwithinthiswork,therefore,isaroadmaptofillthisgap, tiontechniques,andtoexplorethisexpansivefield,weproexploringthepotentialofLLMsforHP. pose a taxonomic framework that highlights the identified WehaveanalyzedexistingliteratureonAPwithLLMs,as methods.ThisclassificationmainlydrawsfromAP\u2019sstatewell as current reviews (Pallagani et al. 2024; Huang et al. of-the-art, so many of these methods also apply to AP. To 2024;Valmeekametal.2022).Observingthatmostmethods provide context for the subsequent sections, we include ilin AP that are similarly applicable to HP, we have classilustrative examples of remarkable AP Integration methods fiedthesemethods,buildingataxonomytobringHPcloser fromcurrentliterature.Eachofthemethodswithinthistaxto the existing LLM integration techniques. Our taxonomy onomyrepresentsasubsetoftechniquesratherthanaprecise classifiestheintegrationmethodsaccordingtotwodifferent implementation, and may encompass multiple approaches. dimensions:thePlanningProcessRole(inwhichpartofthe Furthermore,thesemethodsarenon-exclusive,meaningthat HP life cycle is the LLM applied - i.e. problem definition, planningagentscanbedesignedtoexploremultiplecombiplanelaborationorpost-processing)andtheLLMImprovenations,makingthisahugefieldtoexplore.ThisclassificamentStrategy(whichLLM-basedapproachareusedtoimtionisintendedtobeastartingpoint,notafixedframework, prove the LLM performance - i.e. giving extra knowledge withroomforexplorationandrefinement. ormakingmultiple calls).GiventhatHP isasubsetof AP, thisclassificationisbroadlyapplicabletoAPaswell.",
      "chunk_index": 0,
      "word_count": 363,
      "token_count": 471,
      "metadata": {
        "start_char": 0,
        "end_char": 4655,
        "has_overlap": false,
        "sentence_count": 19
      }
    },
    {
      "chunk_id": "2501_chunk_1",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "Our taxonomy onomyrepresentsasubsetoftechniquesratherthanaprecise classifiestheintegrationmethodsaccordingtotwodifferent implementation, and may encompass multiple approaches. dimensions:thePlanningProcessRole(inwhichpartofthe Furthermore,thesemethodsarenon-exclusive,meaningthat HP life cycle is the LLM applied - i.e. problem definition, planningagentscanbedesignedtoexploremultiplecombiplanelaborationorpost-processing)andtheLLMImprovenations,makingthisahugefieldtoexplore.ThisclassificamentStrategy(whichLLM-basedapproachareusedtoimtionisintendedtobeastartingpoint,notafixedframework, prove the LLM performance - i.e. giving extra knowledge withroomforexplorationandrefinement. ormakingmultiple calls).GiventhatHP isasubsetof AP, thisclassificationisbroadlyapplicabletoAPaswell. 1WebsiteoftheIPC-2023:https://ipc2023-htn.github.io voN ]IA.sc[ 2v86080.1052:viXra Our proposed taxonomy is structured along two dimen- Actions sions:thePlanningProcessRole,categorizingthestagesof Tasks Generation the HP life cycle where an LLM can be applied: problem InitialState definition,planelaborationandpost-processing(i.e.,includ- Goal ProblemDefinition ingplantranslationandexplanationtofinaluser).AndLLM Actions Improvement Strategy, which encompasses general strate- Tasks Translation gies used to enhance LLM performance, which are appli- InitialState cableregardlessoftheroletheyareusedfor:knowledgeen- Goal hancementandmultiplecalls.Inthislastdimension,despite LLMPlanner several LLM Reasoning Strategies have been studied, we havefocusedourclassificationonthemaindifferentstrate- Expansion gies that, we have observed, are commonly used in AP, as Selection we consider that are the most interesting techniques to ini- Elicitation PlanElaboration tially explore and evaluate in HP. These strategies mainly GraphSearch Backtracking consistonusingextraknowledgeoraugmentingthenumber Heuristic ofLLMexecutions. Aggregation Pruning PlanningProcessRole Preferences Guidance Initialization LLMs can assume various roles across the three general TranslatingthePlan stepsofaplanningprocess:(1)problemdefinition,(2)plan Post-Processing ExplainingthePlan elaboration,and(3)post-processing.EachstepisfurtherdividedintothedistinctiveLLMintegrationmethodsobserved Table1:SummaryofthepossiblerolesthatanLLMcanperintheliterature.Table1summarizesthisclassification. formduringtheHPlifecycle.Thisclassificationisdetailed Problem Definition. An HP Problem includes the same inthePlanningProcessRolesection. elementsasanAPproblem(Actions,InitialStateandGoal), alongwiththehigh-levelactions(Tasks)thatrepresentsthe hierarchical information about the environment. Each ele- \u2022 Planning Guidance. Here, the LLM is external to the mentcanbegeneratedusinganLLMthroughtwomainapplanner,butassistsitbyprovidingassistance.Thisguidproaches:Translation,whenallnecessaryinformationisexance can be an initial plan that the planner can refine plicitlyandpreviouslyprovidedandweonlywanttheLLM (Valmeekam et al. 2023) or environment preferences to to restructure the provided information into a target format narrowthesearchspace(Sharanetal.2023). (Liu et al. 2023); and Generation, when the information is partially or implicitly provided, so the LLM is inferring or Post-Processing Once a plan is developed, an LLM can assumingmissinginformationbasedonreasoning(Gestrin, beusedtorefineit,byTranslatingtheplanintoanotherdata Kuhlmann,andSeipp2024). structure or language, typically an executable format (e.g. forarobottorunit)ornaturallanguage(Liuetal.2023).Or Plan Elaboration We categorize this group based on the Explaining the Plan, where de LLM has to generate more roleoftheLLMintheproblemsolvingprocess: detailed information, commonly in natural language, based ontheprovidedplan(SimonandMuise2022). \u2022 LLM Planner. In this basic setup, the LLM itself LLMImprovementStrategies functions as the planner (Silver et al. 2022). While LLMimprovementstrategiescanbeapplied,thereisnot WhenperforminganytaskusinganLLM,itcanbedirectly external planner or explicit search process here, so the executed to obtain an output. However, their results are of- LLM the model is responsible for the entire planning tensuboptimal.Toaddressthis,therearesomestrategiesto process. enhancetheLLMperformancewhichhavebeenusedinseveral reasoning-related fields, as math, question answering \u2022 Graph Search. The LLM is embedded in the planner, or AP. Building on this foundation, we have identified the whichisdonewithinanexplicitsearchalgorithm,where strategies commonly used in AP, and extended them to the the LLM can perform one or more roles, like Node ExspecificcaseofHP.Inthissection,weproposeaclassificapansion (generating the next possible actions), SelectionofstrategiesthatcanbeemployedinHPtoimprovethe tion(choosingthenextaction),Heuristicprovision(scor- LLMperformance,regardlessoftheroletheyareusedfor.",
      "chunk_index": 1,
      "word_count": 400,
      "token_count": 520,
      "metadata": {
        "start_char": 3873,
        "end_char": 8730,
        "has_overlap": true,
        "sentence_count": 26
      }
    },
    {
      "chunk_id": "2501_chunk_2",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "Building on this foundation, we have identified the whichisdonewithinanexplicitsearchalgorithm,where strategies commonly used in AP, and extended them to the the LLM can perform one or more roles, like Node ExspecificcaseofHP.Inthissection,weproposeaclassificapansion (generating the next possible actions), SelectionofstrategiesthatcanbeemployedinHPtoimprovethe tion(choosingthenextaction),Heuristicprovision(scor- LLMperformance,regardlessoftheroletheyareusedfor. ingstates),ModelElicitation,Backtracking,Aggregation LLM performance can be enhanced by either providing and Pruning. Some remarkable architectures are RAP moreknowledgeabouttheproblemorincreasingthenumber (Haoetal.2023),integratinganLLMintoaMCTSPlanof LLM calls used during problem-solving. Each of these ner; GoT (Besta et al. 2024), implementing an LLM in approachesisalsocategorizedintothedistinctivestrategies. mostofthementionedrolestosolvereasoningproblems; This classification is detailed along next subsections and andSayCan(Ahnetal.2022),whichutilizesanLLMas summarized in Table 2. Note that these strategies are neiaprobabilisticrelevance(heuristic)scorer. ther mandatory nor mutually exclusive, meaning that it is possibletousenone,some,orallofthemsimultaneously. Fine-tuning Previous Prompting KnowledgeEnhancement WecansplittheLLMknowl- ChainofThoughts Knowledge edge enhancement strategies into two main perspectives: Reinforcement withpreviousknowledge(providingadditionalinformation Feedback PromptCorrection relevanttotheproblembeforestartingtosolveit)orthrough Memory feedback(themodelisiterativelyprovidedwithextrainfor- SequentialCalls Decomposition mationbasedonitspreviousoutputs,whilesolvingthetask). ParallelCalls Multi-Calls Bothperspectives,moreover,mayhavedifferentapproaches SequentialCalls Revision dependingonthelocationwheretheknowledgeisapplied: ParallelCalls \u2022 Previous. This approach involves providing extra infor- Table2:Summaryofthepossiblestrategiesthatcanbefolmation to the LLM before its execution. Fine-tuning is lowedtoimprovetheLLM\u2019sperformancewithintheHPlife thetraditionalmethodinthefieldofdeeplearning,which cycle, regardless of the specific role. This classification is involvesadjustingthemodel\u2019sinternalweightswithsupdetailedintheLLMImprovementStrategiessection. plementary data (Pallagani et al. 2022). Alternatively, knowledgecanbedirectlyprovidedthroughthemodel\u2019s prompt, which is a more flexible and accessible option twodifferentapproaches,dependingonwhetheranoutputis than fine-tuning, as it does not require a training prousedforthenextcallornot(SequentialorParallelcalls). cess. Providing extra information is achieved through input-outputexamples(shots)thatenhancegeneratedre- \u2022 Decomposition. A problem can be sequentially decomsponses (Song et al. 2023). If the shots provide useposed: each LLM call\u2019s output generates an intermedifulenvironmentalinformation(e.g.,domaininformation) ate step that is utilized for the next call\u2019s input. For inthis is called in-context prompting; if they only aim to stance, to generate a plan, we could iteratively ask the elicitanspecificoutputstructure,itisreferredtoasout- LLM to only generate the next action of a partial plan, of-context prompting. Furthermore, we can also provide than attempting to generate the entire plan in a single knowledge about how to reason, about the problem itcall(Huangetal.2022).Otherwise,theproblemcanbe self. Chain of Thoughts (CoT) (Wei et al. 2022) is the decomposedinparallel:eachLLMcallcanreturnsalist best example of this, a different prompting strategy that simplersub-problemswhichcanbeindependentlysolved encouragestheLLMtogenerateareasoningprocessbe- (i.e.theclassicalDivideandConquerstrategy).Thisisilforeprovidingthefinalanswer.Thisistypicallyachieved lustrativelyusedinGenerativeAgents(Parketal.2023). by using few-shot prompting with reasoning examples, \u2022 Revision.Wecanmakethemultiplecallstosequentially thoughreasoningcanalsobeelicitedwithoutexamples, refinetheLLM\u2019soutput:weasktheLLMtoinitiallygive knownasZero-shotCoT (Kojimaetal.2022). us a complete but simple (general) solution that itera- \u2022 Feedback.Unlikethepreviousparadigm,heretheextra tivelybecomesmoredetailedthroughthecalls(Liuetal. informationisprovidedduringthetasksolvingprocess: 2024).Otherwise,wecandoaparallelapproachbyaskratherthansimplyacceptingtheoutputofanLLMexe- ingtheLLMtoentirelysolvetheproblemmultipletimes cution,wecaniterativelyimprovetheresultoftheLLM and, then, combine the different results into a final outby providing it feedback based on its previous outputs. put. Self-consistency (Wang et al. 2022) is a prominent This feedback can come from various sources (humans, approach,whichcombinestheseveraloutputsbyselectthe environment, an external module, another LLM, ing the most common response, but various criteria can etc. ).ReinforcementLearningistheclassicalmethodof beusedtochoosethefinaloutput.",
      "chunk_index": 2,
      "word_count": 402,
      "token_count": 522,
      "metadata": {
        "start_char": 8265,
        "end_char": 13164,
        "has_overlap": true,
        "sentence_count": 32
      }
    },
    {
      "chunk_id": "2501_chunk_3",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "put. Self-consistency (Wang et al. 2022) is a prominent This feedback can come from various sources (humans, approach,whichcombinestheseveraloutputsbyselectthe environment, an external module, another LLM, ing the most common response, but various criteria can etc. ).ReinforcementLearningistheclassicalmethodof beusedtochoosethefinaloutput. learning from feedback in machine learning, where the knowledgeisappliedbymodifyingthemodel\u2019sinternal Benchmark weights,basedonarewardscore(Yaoetal.2020).Alter- Hierarchical Task Networks (HTN) Planning (Nau et al. natively,feedbackcanbeusedtodynamicallyadjustand 2003)isthemostwidelyusedandstudiedapproachwithin improve the prompt (Prompt Correction), where promitheHPfield,makingitasuitablereferencepointforexperinent examples in the literature are Self-Refine (Madaan mentingwithandevaluatingvariousLLMintegrationmethet al. 2024) and Reflexion (Shinn et al. 2024). Finally, ods.Weproposeusingthetotal-ordertrackfromIPC-2023, themodel\u2019slearningcanalsoberepresentedthroughan whichcontains22domains,eachwithdozensofproblems. externalMemoryModule,beingVoyageranotablearchi- Adetailedbreakdownofthisinformation,alongwithasumtecturethatusesthisapproach(Wangetal.2023). maryoftheexperimentalresults,isprovidedinTable3. Multiple Calls To improve the LLM\u2019s performance To assess and compare the performance of future imthroughmultiplecalls,therearetwomainperspectives:the plementations, we establish two reference points. First, we problem can be divided into simpler sub-problems that the consider the winner of the IPC-2023 Total-Order Satisfic- LLMsolveoneachcall(Decomposition);ortheLLMsolves ingtrack,PandaDealer-agile-lama(Olz,Ho \u0308ller,andBercher the whole problem several times and we take advantage of 2023)asanupperbound,asitrepresentsthecurrentstateof the varied information generated by the multiple outputs the art in HP solvers. Second, we include as baseline a ba- (Revision).Bothperspectivescanalsobeaddressedthrough sicLLMPlanner(i.e.usinganLLMdirectlytoplanwithout providing any LLM Improvement Strategy) representing a Panda LLMPlanner lowerboundforLLMIntegration.Thisapproach,beingthe Domain N Score FP CP FD CD simplest method in our taxonomy, serves as a foundational Assembly 30 0.89 15 3 0 0 pointofcomparisonandastartingpointfortheroadmap. Barman 20 0.78 4 1 0 0 Blocks 30 0.77 9 0 1 0 ExecutionandExperimentationConsiderations Depots 30 0.90 4 0 0 0 Factories 20 0.67 6 0 0 0 ThePandaDealerscorewithinthedatasethavebeensourced Freecell 60 0.13 38 18 0 0 from the published IPC-2023 results. This score represents theratioC\u2217/Cbetweenthecostofareferenceplan(C\u2217)and Hiking 30 0.83 0 0 0 0 thebestobtainedplan(C).Duetotheunavailabilityofthese lamps 30 0.48 5 1 1 0 Logistics 80 0.98 14 1 1 0 reference plans, we could not compute the same score for Multiarm 74 0.95 30 0 2 0 theLLMPlanner.Nonetheless,thisscoreservesasareliable Robot 20 0.92 13 1 5 0 referenceforassessingthequalityofPandaDealer\u2019sperfor- Satellite 20 0.92 11 0 2 0 mance.Forgenerativeplans,however,additionalproperties Towers 20 0.65 5 0 0 0 needtobeevaluated,suchassemanticcoherencewithinthe Transport 40 0.73 10 0 4 0 plan(whichdoesnotneedtobemeasuredinsymbolicplan- Woodwork 30 0.69 26 0 0 0 ners). To address this, we adopted alternative metrics more suitable for analyzing the quality of generative plans: Plan Total 614 14.42 190 25 16 0 Feasibility(theplanissyntacticallycorrect),PlanCorrect- Average: 0.80 0.31 0.04 0.03 0 ness(itisexecutableandreachesagoalstate),Decomposition Feasibility (the hierarchical decomposition of the plan Table3:Summaryoftheinformationprovidedbythebenchissyntacticallycorrect)andDecompositionCorrectness(the mark, listing the number of problems in each domain of decompositionalignswiththegeneratedplan). the dataset and the performance reported by each planner. WeutilizeLlama-3.1-Nemotron-70B-Instruct,oneofthe The score of PandaDealer is the one provided by the IPChighest-performing LLMs available (Wang et al.",
      "chunk_index": 3,
      "word_count": 401,
      "token_count": 521,
      "metadata": {
        "start_char": 12823,
        "end_char": 16798,
        "has_overlap": true,
        "sentence_count": 19
      }
    },
    {
      "chunk_id": "2501_chunk_4",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "the dataset and the performance reported by each planner. WeutilizeLlama-3.1-Nemotron-70B-Instruct,oneofthe The score of PandaDealer is the one provided by the IPChighest-performing LLMs available (Wang et al. 2024), as 2023 results. The scores utilized for the LLM Planner are the LLM Planner. We utilize the official IPC verifier to explained in the Benchmark section, representing the numscorethegeneratedplansalongthedifferentproposedmet- ber of feasible plans (FP), correct plans (CP), feasible derics. The execution and validation source codes, as well as compositions(FD)andcorrectdecompositions(CD). the generated plans, and obtained results are allocated on GitHub.URL:https://github.com/Corkiray/HTN-LLM. Conclusion ResultsDiscussions In this preliminary work, we have obtained the results for In this work, we propose a roadmap to guide future re- 15 out of the 23 domains in the dataset, not the complete search in the integration of LLMs and HP, as this remains set, due to temporal and computational limitations. Neveralargelyunexploredfield.Thisroadmapiscenteredontwo theless, these results are sufficient to illustrate the notably key contributions: a taxonomy and a benchmark. The taxlow performance of the LLM Planner, which is expected onomycategorizesthemainintegrationmethods,structured given the simplicity of the method and the absence of any along two dimensions: the first one considers the various LLM Improvement Strategies. As shown in Table 3, the roles that an LLM could fulfill within the HP life cycle. LLMPlannerfailstogeneratefeasibleplansinnearly70% ThesecondonefocusesonstrategiestoenhanceLLMperof the problems, highlighting the LLM\u2019s limited ability to formance, irrespective of the specific role in which they interpretandadheretoaspecificformat.Evenmoreremarkare applied. The benchmark introduces a dataset and proable is the proportion of correct plans: with only 4% (i.e. vides initial results that serves as reference in subsequent 13%ofthefeasibleplans),itshowsthedifficultythatabaexperimentation. These results include the performance of sicLLMencountersinplanningcorrectly.Asimilartrendis astate-of-the-artHPsolverandanLLMPlannerusingone observed in the number of feasible decompositions which, ofthebest-performingLLMsavailable,butwithoutleveragwith only 3% correct, indicates a significant performance ing any improvement strategy. As expected, the results redropinhandlingaspecificformatwithincreasingcomplex- veal the LLM\u2019s limited performance in solving HP probity.Interestingly,correctplansandfeasibledecompositions lems, but they establishes a baseline to evaluate succeedare often disjoint (i.e. the LLM achieves either one result ing improvements. Promising future directions include exor the other, but not both). Consequentially, the LLM has ploring the planning capabilities of an LLM Planner augbeenunabletoproduceacorrecthierarchicaldecomposition mented with improvement Strategies to overcome the limforanyproblem.Thisobservationisexplainableconsidering itations identified in this study. Furthermore, exploring intheLLM\u2019sinherentarchitectureasatransformer,whichoptegration in additional aspects of the HP life cycle, such as erateswithinastaticcomputationalcapacity.AnLLMcan- PlanMonitoringorExceptionManagement,isbeneficialto notdynamicallyadjustitsprocessingtimebasedonproblem expand the boundaries of the proposed taxonomy. Finally, complexity,andasaresult,itsabilitytoaddressmultiplededeveloping new architectures within the outlined Planning mandingrequirementssimultaneously(i.e.plancorrectness ProcessRolesoffersapathwaytosystematicallyinvestigate anddecompositionfeasibility)islimited. andadvancethisunexploredfield.",
      "chunk_index": 4,
      "word_count": 388,
      "token_count": 504,
      "metadata": {
        "start_char": 16589,
        "end_char": 20274,
        "has_overlap": true,
        "sentence_count": 22
      }
    },
    {
      "chunk_id": "2501_chunk_5",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "Furthermore, exploring intheLLM\u2019sinherentarchitectureasatransformer,whichoptegration in additional aspects of the HP life cycle, such as erateswithinastaticcomputationalcapacity.AnLLMcan- PlanMonitoringorExceptionManagement,isbeneficialto notdynamicallyadjustitsprocessingtimebasedonproblem expand the boundaries of the proposed taxonomy. Finally, complexity,andasaresult,itsabilitytoaddressmultiplededeveloping new architectures within the outlined Planning mandingrequirementssimultaneously(i.e.plancorrectness ProcessRolesoffersapathwaytosystematicallyinvestigate anddecompositionfeasibility)islimited. andadvancethisunexploredfield. Acknowledgment Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Horesh, L.; Srivastava, B.; Fabiano, F.; and Loreggia, A. This work has been partially funded by the Grant 2022. Plansformer:Generatingsymbolicplansusingtrans- PID2022-142976OB-I00, funded by MICIU/AEI/ formers. arXivpreprintarXiv:2212.08681. 10.13039/501100011033andby\u201cERDF/EU\u201d. Pallagani,V.;Muppasani,B.C.;Roy,K.;Fabiano,F.;Loreggia,A.;Murugesan,K.;Srivastava,B.;Rossi,F.;Horesh,L. ; References andSheth,A.2024. Ontheprospectsofincorporatinglarge Ahn, M.; Brohan, A.; Brown, N.; Chebotar, Y.; Cortes, O.; languagemodels(llms)inautomatedplanningandschedul- David, B.; Finn, C.; Fu, C.; Gopalakrishnan, K.; Hausman, ing(aps). InProceedingsoftheICAPS. K.;etal.2022.Doasican,notasisay:Groundinglanguage Park,J.S.;O\u2019Brien,J.;Cai,C.J.;Morris,M.R.;Liang,P. ; inroboticaffordances. arXivpreprintarXiv:2204.01691. and Bernstein, M.\n\nS. 2023. Generative agents: Interactive Besta, M.; Blach, N.; Kubicek, A.; Gerstenberger, R.; simulacraofhumanbehavior. InProceedingsoftheUIST. Podstawski, M.; Gianinazzi, L.; Gajda, J.; Lehmann, T.; Sharan,S.;Pittaluga,F.;Chandraker,M.;etal.2023. Llm- Niewiadomski, H.; Nyczyk, P.; et al. 2024. Graph of assist:Enhancingclosed-loopplanningwithlanguage-based thoughts: Solving elaborate problems with large language reasoning. arXivpreprintarXiv:2401.00125. models. InProceedingsoftheAAAI. Shinn, N.; Cassano, F.; Gopinath, A.; Narasimhan, K.; and Dai,Z.;Asgharivaskasi,A.;Duong,T.;Lin,S.;Tzes,M.-E. ; Yao,S.2024. Reflexion:Languageagentswithverbalrein- Pappas, G.; and Atanasov, N. 2024. Optimal scene graph forcementlearning. InProceedingsoftheNeurIPS. planningwithlargelanguagemodelguidance. InProdeec- Silver, T.; Hariprasad, V.; Shuttleworth, R.\n\nS.; Kumar, N.; ingoftheICRA. Lozano-Pe \u0301rez, T.; and Kaelbling, L.\n\nP. 2022. PDDL plan- Gestrin, E.; Kuhlmann, M.; and Seipp, J. 2024. NL2Plan: ningwithpretrainedlargelanguagemodels. InProceedings RobustLLM-Driven Planningfrom MinimalText DescripoftheNeurIPS. tions. arXivpreprintarXiv:2405.04215. Simon,N.;andMuise,C.2022. TattleTale:storytellingwith Hao,S.;Gu,Y.;Ma,H.;Hong,J.J.;Wang,Z.;Wang,D.Z. ; planningandlargelanguagemodels. InProceedingsofthe and Hu, Z. 2023. Reasoning with language model is plan- ICAPSSPARK. ningwithworldmodel. arXivpreprintarXiv:2305.14992. Song, C.\n\nH.; Wu, J.; Washington, C.; Sadler, B.\n\nM.; Chao, Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I. 2022. W.-L.; and Su, Y. 2023. Llm-planner: Few-shot grounded Language models as zero-shot planners: Extracting actionplanning for embodied agents with large language models. ableknowledgeforembodiedagents. InProceedingsofthe InProceedingsoftheICCV. ICML. Tse,C.2024. ImprovingHuman-RobotCommunicationof HierarchicalTaskPlanningthroughLLMs. BrownUniver- Huang, X.; Liu, W.; Chen, X.; Wang, X.; Wang, H.; Lian, sity. D.; Wang, Y.; Tang, R.; and Chen, E. 2024. Understanding the planning of LLM agents: A survey. arXiv preprint Valmeekam, K.; Olmo, A.; Sreedharan, S.; and KambhamarXiv:2402.02716. pati, S. 2022. Large language models still can\u2019t plan (a benchmark for LLMs on planning and reasoning about Kojima, T.; Gu, S.\n\nS.; Reid, M.; Matsuo, Y.; and Iwasawa, change). InProceedingsoftheNeurIPS. Y.2022. Largelanguagemodelsarezero-shotreasoners. In ProceedingsoftheNeurIPS. Valmeekam, K.; Sreedharan, S.; Marquez, M.; Olmo, A.; and Kambhampati, S. 2023. On the planning abilities of Liu,B.;Jiang,Y.;Zhang,X.;Liu,Q.;Zhang,S.;Biswas,J. ; large language models (a critical investigation with a proand Stone, P. 2023. Llm+ p: Empowering large language posedbenchmark). arXivpreprintarXiv:2302.06706. models with optimal planning proficiency. arXiv preprint Wang,G.;Xie,Y.;Jiang,Y.;Mandlekar,A.;Xiao,C. ;Zhu, arXiv:2304.11477. Y.;Fan,L.;andAnandkumar,A.2023.",
      "chunk_index": 5,
      "word_count": 408,
      "token_count": 530,
      "metadata": {
        "start_char": 19638,
        "end_char": 24062,
        "has_overlap": true,
        "sentence_count": 72
      }
    },
    {
      "chunk_id": "2501_chunk_6",
      "paper_id": "2501",
      "paper_title": "We use Llama-3.1-Nemotron-70B-Instruct (Wang within the HP life cycle.",
      "section": "Full Text",
      "text": "On the planning abilities of Liu,B.;Jiang,Y.;Zhang,X.;Liu,Q.;Zhang,S.;Biswas,J. ; large language models (a critical investigation with a proand Stone, P. 2023. Llm+ p: Empowering large language posedbenchmark). arXivpreprintarXiv:2302.06706. models with optimal planning proficiency. arXiv preprint Wang,G.;Xie,Y.;Jiang,Y.;Mandlekar,A.;Xiao,C. ;Zhu, arXiv:2304.11477. Y.;Fan,L.;andAnandkumar,A.2023. Voyager:Anopen- Liu, Y.; Palmieri, L.; Koch, S.; Georgievski, I.; and Aiello, ended embodied agent with large language models. arXiv M. 2024. Delta: Decomposed efficient long-term robot preprintarXiv:2305.16291. task planning using large language models. arXiv preprint Wang,X.;Wei,J.;Schuurmans,D.;Le,Q.;Chi,E. ;Narang, arXiv:2404.03275. S.; Chowdhery, A.; and Zhou, D. 2022. Self-consistency Madaan, A.; Tandon, N.; Gupta, P.; Hallinan, S.; Gao, L.; improves chain of thought reasoning in language models. Wiegreffe, S.; Alon, U.; Dziri, N.; Prabhumoye, S.; Yang, arXivpreprintarXiv:2203.11171. Y.; et al. 2024. Self-refine: Iterative refinement with self- Wang,Z.;Bukharin,A.;Delalleau,O.;Egert,D.;Shen,G. ; feedback. InProceedingsoftheNeurIPS. Zeng, J.; Kuchaiev, O.; and Dong, Y. 2024. HelpSteer2- Nau, D.\n\nS.; Au, T.-C.; Ilghami, O.; Kuter, U.; Murdock, Preference: Complementing Ratings with Preferences. J.W.;Wu,D.;andYaman,F.2003. SHOP2:AnHTNplanarXivpreprintarXiv:2410.01257. ningsystem. Journalofartificialintelligenceresearch. Wei, J.; Wang, X.; Schuurmans, D.; Bosma, M.; Xia, F.; Olz, C.; Ho \u0308ller, D.; and Bercher, P. 2023. The PAN- Chi,E.;Le,Q.V.;Zhou,D.;etal.2022. Chain-of-thought DADealerSystemforTotallyOrderedHTNPlanning. IPC prompting elicits reasoning in large language models. In HTNTracks. ProceedingsoftheNeurIPS. Yang, R.; Zhang, F.; and Hou, M. 2024. Oceanplan: HierarchicalplanningandreplanningfornaturallanguageAUV piloting in large-scale unexplored ocean environments. In Proceedingsofthe18thInternationalConferenceonUnderwaterNetworks&Systems,1-5. Yao,S.;Rao,R.;Hausknecht,M.;andNarasimhan,K.2020. Keepcalmandexplore:Languagemodelsforactiongenerationintext-basedgames. arXivpreprintarXiv:2010.02903.",
      "chunk_index": 6,
      "word_count": 208,
      "token_count": 270,
      "metadata": {
        "start_char": 23663,
        "end_char": 25794,
        "has_overlap": true,
        "sentence_count": 38
      }
    }
  ]
}